{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad0b86d",
   "metadata": {},
   "source": [
    "# Modelos Preditivos de Matemática Aplicada a Ciência de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004548e8",
   "metadata": {},
   "source": [
    "## Modelos Utilizados\n",
    "\n",
    "### Classificação\n",
    "\n",
    "- GaussianNB\n",
    "- DecisionTreeClassifier\n",
    "- KNeighborsClassifier\n",
    "- RandomForestClassifier\n",
    "\n",
    "### Regressão\n",
    "\n",
    "- LinearRegression\n",
    "- DecisionTreeRegressor\n",
    "- KNeighborsRegressor\n",
    "- RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f9c42",
   "metadata": {},
   "source": [
    "### Link do dataset: https://www.kaggle.com/datasets/andriyaniarimbi/predictive-maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9755289a",
   "metadata": {},
   "source": [
    "Obs: Neste projeto temos três datasets, porém para este notebook estamos testando somente o predictive_maintence que verifica se é necessário ou não realizar a manutenção de um ambiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e627e1a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cee53c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modelos\n",
    "\n",
    "### Modelos de classificação\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "### Modelos de Regressão\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## Processamento e normalização de dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "## Testes e Avaliação\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "## Métricas\n",
    "from sklearn.metrics import accuracy_score, r2_score,precision_score, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "\n",
    "from sklearn.base import is_classifier, is_regressor\n",
    "\n",
    "## Serialização\n",
    "import redis\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee870af9",
   "metadata": {},
   "source": [
    "## Processo de carregar e filtrar os dados do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cf2f447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Features (X) head:\n",
      "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
      "0                298.1                    308.6                    1551   \n",
      "1                298.2                    308.7                    1408   \n",
      "2                298.1                    308.5                    1498   \n",
      "3                298.2                    308.6                    1433   \n",
      "4                298.2                    308.7                    1408   \n",
      "\n",
      "   Torque [Nm]  Tool wear [min]  Type_L  Type_M  \n",
      "0         42.8                0   False    True  \n",
      "1         46.3                3    True   False  \n",
      "2         49.4                5    True   False  \n",
      "3         39.5                7    True   False  \n",
      "4         40.0                9    True   False  \n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset em um dataframe\n",
    "df = pd.read_csv('./datasets/predictive_maintenance.csv')\n",
    "\n",
    "# Deletar colunas que não são uteis\n",
    "df_processed = df.drop(['UDI', 'Product ID', 'Target'], axis=1)\n",
    "\n",
    "# Normalização da coluna Failure Type para número\n",
    "label_encoder = LabelEncoder()\n",
    "df_processed['Failure Type'] = label_encoder.fit_transform(df_processed['Failure Type'])\n",
    "\n",
    "# A coluna 'Type' é uma feature. Vamos usar a codificação one-hot para converter\n",
    "# Isso impede que o modelo pense que 'L' < 'M' < 'H'.\n",
    "df_processed = pd.get_dummies(df_processed, columns=['Type'], drop_first=True)\n",
    "\n",
    "# Separando as colunas preditada e o resto\n",
    "X = df_processed.drop('Failure Type', axis=1)\n",
    "y = df_processed['Failure Type']\n",
    "\n",
    "print(\"\\nProcessed Features (X) head:\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca2098fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Failure Type</th>\n",
       "      <th>Type_L</th>\n",
       "      <th>Type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>298.8</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1604</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>298.9</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1632</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>299.0</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1645</td>\n",
       "      <td>33.4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>48.5</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1500</td>\n",
       "      <td>40.2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
       "0                   298.1                    308.6                    1551   \n",
       "1                   298.2                    308.7                    1408   \n",
       "2                   298.1                    308.5                    1498   \n",
       "3                   298.2                    308.6                    1433   \n",
       "4                   298.2                    308.7                    1408   \n",
       "...                   ...                      ...                     ...   \n",
       "9995                298.8                    308.4                    1604   \n",
       "9996                298.9                    308.4                    1632   \n",
       "9997                299.0                    308.6                    1645   \n",
       "9998                299.0                    308.7                    1408   \n",
       "9999                299.0                    308.7                    1500   \n",
       "\n",
       "      Torque [Nm]  Tool wear [min]  Failure Type  Type_L  Type_M  \n",
       "0            42.8                0             1   False    True  \n",
       "1            46.3                3             1    True   False  \n",
       "2            49.4                5             1    True   False  \n",
       "3            39.5                7             1    True   False  \n",
       "4            40.0                9             1    True   False  \n",
       "...           ...              ...           ...     ...     ...  \n",
       "9995         29.5               14             1   False    True  \n",
       "9996         31.8               17             1   False   False  \n",
       "9997         33.4               22             1   False    True  \n",
       "9998         48.5               25             1   False   False  \n",
       "9999         40.2               30             1   False    True  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Vizualiação do dataframe \n",
    "display(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be6f4dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 5, 2, 4, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo valores únicos da coluna que vai ser prevista \n",
    "df_processed['Failure Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccf2762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de linhas de Treinamento: (8000, 7)\n",
      "\n",
      "Quantidade de linhas de Teste: (2000, 7)\n"
     ]
    }
   ],
   "source": [
    "#Definindo dados de teste e dados de treino \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nQuantidade de linhas de Treinamento: {x_train.shape}\")\n",
    "print(f\"\\nQuantidade de linhas de Teste: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60ccee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train normalizado:\n",
      "      Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
      "9254            -0.854066                -0.609589                0.427634   \n",
      "1561            -0.904014                -1.080528               -0.834945   \n",
      "1670            -0.904014                -1.484190               -0.059677   \n",
      "6087             0.444571                 0.534121                0.333495   \n",
      "6669             0.694309                 0.332290                0.178441   \n",
      "\n",
      "      Torque [Nm]  Tool wear [min]  Type_L  Type_M  \n",
      "9254    -0.892696         1.375035    True   False  \n",
      "1561     1.382187         0.457620    True   False  \n",
      "1670    -0.892696         1.359218    True   False  \n",
      "6087    -0.702288        -1.598655   False    True  \n",
      "6669    -0.612094         1.580663    True   False  \n"
     ]
    }
   ],
   "source": [
    "# Colunas que são numericas e precisam de normalização\n",
    "numerical_features = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "\n",
    "#Inicializar o scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Colocar o scaler para aprender os parâmetros de normalização (média e desvio padrão) a partir dos dados de treino\n",
    "scaler.fit(x_train[numerical_features])\n",
    "\n",
    "# Transoformar os dados de treino e teste\n",
    "x_train[numerical_features] = scaler.transform(x_train[numerical_features])\n",
    "x_test[numerical_features] = scaler.transform(x_test[numerical_features])\n",
    "\n",
    "print(\"\\nX_train normalizado:\")\n",
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa5427",
   "metadata": {},
   "source": [
    "## Classificação do modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40b1c289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos na variável alvo: 6\n",
      "Exemplos de valores: [1 3 5 2 4 0]\n",
      "\n",
      "Tipo de problema detectado: CLASSIFICACAO\n"
     ]
    }
   ],
   "source": [
    "# --- Determinar o tipo de problema ---\n",
    "# Número de valores distintos na variável alvo\n",
    "unique_values = y.nunique()\n",
    "print(f\"\\nValores únicos na variável alvo: {unique_values}\")\n",
    "print(f\"Exemplos de valores: {y.unique()[:10]}\")\n",
    "\n",
    "# Verifica o tipo de problema\n",
    "if y.dtype == 'object' or unique_values < 20:\n",
    "    problema = \"classificacao\"\n",
    "else:\n",
    "    problema = \"regressao\"\n",
    "\n",
    "print(f\"\\nTipo de problema detectado: {problema.upper()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b7d4f",
   "metadata": {},
   "source": [
    "# Modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b06196",
   "metadata": {},
   "source": [
    "### Justificativa dos paramêtros para validação Cruzada\n",
    "\n",
    "### Modelos de Classificação\n",
    "#### GaussianNB\n",
    "- O var_smoothing evita divisões por 0 na hora de calcular probabilidade e adiciona um valor de variância.\n",
    "- A escolha do np.logspace é porque o intervalo descrito cobre uma boa faixa logarítmica visto que a função é muito sensível a números pequenos e com uma escala logarítmica ela fica mais estável e garante melhores resultados.\n",
    "\n",
    "#### DecisionTreeClassifier\n",
    "- Crtitérios: Gini e Entropia, ambos são modelos pra prever uma coluna de forma de classificação.\n",
    "\n",
    "- max_depth: limita a profundidade da árvore.\n",
    "    - Valores pequenos evitam overfitting, mas podem gerar underfitting.\n",
    "    - None permite crescer até o limite dos dados (controle total).\n",
    "    - 10, 20, 30 são escolhas típicas de compromisso entre precisão e generalização.\n",
    "\n",
    "- min_samples_split: número mínimo de amostras para dividir um nó.\n",
    "    - [2, 5, 10] cobre desde divisão agressiva (2) até árvores mais generalistas.\n",
    "\n",
    "#### KNNClassifier\n",
    "- n_neighbors: número de vizinhos para votar.\n",
    "    - [3, 5, 7, 9, 11] cobre casos de baixo a médio número de vizinhos.\n",
    "    - Valores muito grandes diluem as fronteiras de decisão e resultam na perda de precisão.\n",
    "\n",
    "- weights:\n",
    "    - \"uniform\": todos vizinhos têm peso igual.\n",
    "    - \"distance\": vizinhos mais próximos têm mais influência → tende a melhorar modelos com ruído.\n",
    "\n",
    "- metric:\n",
    "    - \"euclidean\": padrão em dados contínuos.\n",
    "    - \"manhattan\": mais robusto quando há outliers.\n",
    "\n",
    "#### RandomForestClassifier\n",
    "- n_estimators: número de árvores.\n",
    "    - [100, 200] é suficiente para estabilizar o modelo sem sobrecarregar o treino.\n",
    "\n",
    "- max_depth, min_samples_split, min_samples_leaf, max_features, criterion:\n",
    "    - Mesmos significados e motivações do DecisionTree, mas aqui são testados em conjunto dentro do ensemble.\n",
    "\n",
    "### Modelos de Regressão\n",
    "\n",
    "#### LinearRegression\n",
    "\n",
    "- fit_intercept: define se o modelo calcula o termo b (intercepto).\n",
    "    - True: padrão, útil quando os dados não estão centrados.\n",
    "    - False: útil se você já normalizou ou centralizou os dados.\n",
    "\n",
    "- copy_X: se copia ou não o array original.\n",
    "    - False economiza memória (útil em datasets grandes).\n",
    "    - True é mais seguro (não modifica os dados originais).\n",
    "\n",
    "#### RandomForestRegressor\n",
    "\n",
    "- Mesmas justificativas do RandomForestClassifier.\n",
    "- O criterion = 'squared_error' é padrão para regressão, pois mede o erro médio quadrático entre previsão e real.\n",
    "\n",
    "#### KNeighborsRegressor\n",
    "\n",
    "- n_neighbors, weights, metric tem as mesmas ideias que no KNNClassifier.\n",
    "\n",
    "- algorithm: define o método de busca de vizinhos.\n",
    "    - \"auto\": escolhe automaticamente.\n",
    "    - \"ball_tree\" / \"kd_tree\": eficientes em dados numéricos.\n",
    "    - \"brute\": busca exata (mais lenta, mas serve de controle).\n",
    "\n",
    "- leaf_size: controla a granularidade das árvores internas (afeta tempo x precisão).\n",
    "\n",
    "- p:\n",
    "    - 1 é a distância de Manhattan.\n",
    "    - 2 é a distância Euclidiana (padrão).\n",
    "\n",
    "#### DecisionTreeRegressor\n",
    "\n",
    "- Igual ao DecisionTreeClassifier, mas o criterion muda:\n",
    "- squared_error → mede a soma dos erros quadráticos (regressão)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436eedd",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "535a5d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando GaussianNB...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Melhores parâmetros para GaussianNB: {'var_smoothing': np.float64(1.0)}\n",
      "Adicionado ao Redis com sucesso!\n",
      "\n",
      "Treinando DecisionTreeClassifier...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Melhores parâmetros para DecisionTreeClassifier: {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Adicionado ao Redis com sucesso!\n",
      "\n",
      "Treinando KNNClassifier...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Melhores parâmetros para KNNClassifier: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Adicionado ao Redis com sucesso!\n",
      "\n",
      "Treinando RandomForestClassifier...\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Melhores parâmetros para RandomForestClassifier: {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Adicionado ao Redis com sucesso!\n"
     ]
    }
   ],
   "source": [
    "if problema == \"classificacao\": #Se o problema for classificação\n",
    "    models = {\n",
    "        \"GaussianNB\": (\n",
    "            GaussianNB(),\n",
    "            {\"var_smoothing\": np.logspace(0, -9, num=100)}\n",
    "        ),\n",
    "        \"DecisionTreeClassifier\": (\n",
    "            DecisionTreeClassifier(random_state=42),\n",
    "            {\n",
    "                \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"max_depth\": [None, 10, 20, 30],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "                \"min_samples_leaf\": [1, 2, 4],\n",
    "                \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "            }\n",
    "        ),\n",
    "        \"KNNClassifier\": (\n",
    "            KNeighborsClassifier(),\n",
    "            {\n",
    "                \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "                \"weights\": [\"uniform\", \"distance\"],\n",
    "                \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "            }\n",
    "        ),\n",
    "        \"RandomForestClassifier\": (\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2],\n",
    "                'max_features': ['sqrt', 'log2'],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "\n",
    "else:  #Se problema for regressão\n",
    "    models = {\n",
    "        \"LinearRegression\": (\n",
    "            LinearRegression(),\n",
    "            {\n",
    "                'fit_intercept': [True, False],\n",
    "                'copy_X': [True, False]\n",
    "            }\n",
    "        ),\n",
    "        \"RandomForestRegressor\": (\n",
    "            RandomForestRegressor(),\n",
    "            {\n",
    "                'n_estimators': [100,200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2],\n",
    "                'max_features': ['sqrt', 'log2'],  \n",
    "                'criterion': ['squared_error']  \n",
    "            }\n",
    "        ),\n",
    "        \"KNeighborsRegressor\":(\n",
    "            KNeighborsRegressor(),\n",
    "            {\n",
    "                'n_neighbors': [3,5,7,9,11],\n",
    "                'weights': ['uniform','distance'],\n",
    "                'algorithm': ['auto','ball_tree','kd_tree','brute'],\n",
    "                'leaf_size': [20,30,40,50],\n",
    "                'p': [1,2],\n",
    "                'metric': ['minkowski','euclidean','manhattan']\n",
    "            }\n",
    "        ),\n",
    "        \"DecisionTreeRegressor\":(\n",
    "            DecisionTreeRegressor(),\n",
    "            {\n",
    "                \"criterion\": [\"squared_error\"],\n",
    "                \"max_depth\": [None, 10, 20, 30],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "                \"min_samples_leaf\": [1, 2, 4],\n",
    "                \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "# Dicionários para armazenar resultados\n",
    "best_models = {}\n",
    "metrics = {}\n",
    "\n",
    "# Loop para treinar e avaliar cada modelo\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "\n",
    "    # Detecta automaticamente o tipo do modelo\n",
    "    modelo_tipo = \"regressor\" if is_regressor(model) else \"classificador\"\n",
    "\n",
    "    # Define a métrica de pontuação correta\n",
    "    scoring_metric = 'r2' if modelo_tipo == \"regressor\" else 'accuracy'\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=params,\n",
    "        scoring=scoring_metric,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    gs.fit(x_train, y_train)\n",
    "\n",
    "    print(f\"Melhores parâmetros para {name}: {gs.best_params_}\")\n",
    "\n",
    "    best_model = gs.best_estimator_\n",
    "    best_models[name] = best_model\n",
    "\n",
    "    # prepara dicionário com todas as chaves (garante consistência entre modelos)\n",
    "    model_metrics = {\n",
    "        # Métricas de classificação\n",
    "        \"Accuracy\": np.nan,\n",
    "        \"Precision\": np.nan,\n",
    "        \"Recall\": np.nan,\n",
    "        \"F1-Score\": np.nan,\n",
    "        \"Confusion Matrix\": None,\n",
    "        \"Best Params\": None,\n",
    "        # Métricas de regressão\n",
    "        \"R2\": np.nan,\n",
    "        \"MSE\": np.nan,\n",
    "        \"RMSE\": np.nan,\n",
    "        \"MAE\": np.nan,\n",
    "    }\n",
    "\n",
    "    # Salva os melhores parâmetros e score cross-val do GridSearch\n",
    "    model_metrics[\"Best Params\"] = gs.best_params_\n",
    "    model_metrics[\"CV Score\"] = gs.best_score_\n",
    "\n",
    "    # Previsões no conjunto de teste\n",
    "    y_pred = best_model.predict(x_test)\n",
    "\n",
    "    # Se for regressão, calcula métricas de regressão (e opcionalmente converte para classif.)\n",
    "    if modelo_tipo == \"regressor\":\n",
    "        # métricas de regressão contínuas\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        model_metrics[\"R2\"] = r2\n",
    "        model_metrics[\"MSE\"] = mse\n",
    "        model_metrics[\"RMSE\"] = rmse\n",
    "        model_metrics[\"MAE\"] = mae\n",
    "\n",
    "        # mantém também as métricas de classificação caso queira comparar (conversão por arredondamento)\n",
    "        y_pred_labels = np.rint(y_pred).astype(int)\n",
    "        y_pred_labels = np.clip(y_pred_labels, int(y_test.min()), int(y_test.max()))\n",
    "\n",
    "    else:\n",
    "        # Classificação padrão\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
    "\n",
    "        model_metrics[\"Accuracy\"] = acc\n",
    "        model_metrics[\"Precision\"] = prec\n",
    "        model_metrics[\"Recall\"] = rec\n",
    "        model_metrics[\"F1-Score\"] = f1\n",
    "        model_metrics[\"Confusion Matrix\"] = cm\n",
    "\n",
    "    # salva métricas padronizadas\n",
    "    metrics[name] = model_metrics\n",
    "\n",
    "    # Serialização dos modelos\n",
    "    metrics[name] = model_metrics\n",
    "\n",
    "    # Serialização dos modelos (salva em ./pickles e opcionalmente envia para Redis)\n",
    "    pickle_dir = \"pickles\"\n",
    "\n",
    "    # verifica se a pasta existe antes de criar\n",
    "    if not os.path.isdir(pickle_dir):\n",
    "        os.makedirs(pickle_dir)\n",
    "\n",
    "    # salva o ESTIMADOR ÓTIMO (best_model) com nome do modelo\n",
    "    pickle_path = os.path.join(pickle_dir, f\"{name}.pkl\")\n",
    "    joblib.dump(best_model, pickle_path)\n",
    "\n",
    "    # tenta enviar para redis (chave por modelo); captura erro caso o redis não esteja disponível\n",
    "    try:\n",
    "        r = redis.Redis(host=\"localhost\", port=6379, db=0, decode_responses=False)\n",
    "        with open(pickle_path, \"rb\") as f:\n",
    "            r.set(f\"ml_model:{name}\".encode(), f.read())\n",
    "        print(\"Adicionado ao Redis com sucesso!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Aviso: não foi possível salvar {name} no Redis: {e}\")\n",
    "\n",
    "\n",
    "# Exibe resumo geral das métricas (última célula: separação por tipo)\n",
    "summary_df = pd.DataFrame(metrics).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f6e10",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f69fed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo - Regressão:\n",
      "\n",
      "Nenhum modelo de regressão executado.\n",
      "\n",
      "Resumo - Classificação:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.969</td>\n",
       "      <td>0.945516</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.955933</td>\n",
       "      <td>[[0, 15, 0, 0, 0, 0], [0, 1933, 0, 2, 0, 0], [...</td>\n",
       "      <td>{'var_smoothing': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.969122</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.972152</td>\n",
       "      <td>[[13, 2, 0, 0, 0, 0], [7, 1916, 5, 4, 0, 3], [...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNClassifier</th>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.96424</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.964424</td>\n",
       "      <td>[[4, 11, 0, 0, 0, 0], [3, 1928, 2, 2, 0, 0], [...</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 5, 'wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.972816</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.976714</td>\n",
       "      <td>[[10, 5, 0, 0, 0, 0], [1, 1930, 0, 4, 0, 0], [...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy Precision  Recall  F1-Score  \\\n",
       "GaussianNB                0.969  0.945516   0.969  0.955933   \n",
       "DecisionTreeClassifier   0.9755  0.969122  0.9755  0.972152   \n",
       "KNNClassifier            0.9715   0.96424  0.9715  0.964424   \n",
       "RandomForestClassifier   0.9815  0.972816  0.9815  0.976714   \n",
       "\n",
       "                                                         Confusion Matrix  \\\n",
       "GaussianNB              [[0, 15, 0, 0, 0, 0], [0, 1933, 0, 2, 0, 0], [...   \n",
       "DecisionTreeClassifier  [[13, 2, 0, 0, 0, 0], [7, 1916, 5, 4, 0, 3], [...   \n",
       "KNNClassifier           [[4, 11, 0, 0, 0, 0], [3, 1928, 2, 2, 0, 0], [...   \n",
       "RandomForestClassifier  [[10, 5, 0, 0, 0, 0], [1, 1930, 0, 4, 0, 0], [...   \n",
       "\n",
       "                                                              Best Params  \n",
       "GaussianNB                                         {'var_smoothing': 1.0}  \n",
       "DecisionTreeClassifier  {'criterion': 'gini', 'max_depth': 10, 'max_fe...  \n",
       "KNNClassifier           {'metric': 'manhattan', 'n_neighbors': 5, 'wei...  \n",
       "RandomForestClassifier  {'criterion': 'gini', 'max_depth': None, 'max_...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Garante que 'Best Params' é sempre um dicionário\n",
    "if 'Best Params' in summary_df.columns:\n",
    "    summary_df['Best Params'] = summary_df['Best Params'].apply(\n",
    "        lambda d: d if isinstance(d, dict) else {}\n",
    "    )\n",
    "\n",
    "# Detecta linhas de regressão/classificação\n",
    "if 'R2' in summary_df.columns:\n",
    "    is_regressor = summary_df['R2'].notna()\n",
    "else:\n",
    "    # Detecta regressão pela presença de métricas de erro\n",
    "    regression_metrics = summary_df.filter(regex='MSE|RMSE|MAE|R2')\n",
    "    is_regressor = regression_metrics.notna().any(axis=1)\n",
    "\n",
    "# Diz que o modelo é classificador quando não é regressor e o inverso também\n",
    "is_classifier = is_regressor == False\n",
    "\n",
    "# Colunas relevantes\n",
    "regression_cols = [\"R2\", \"MSE\", \"RMSE\", \"MAE\", \"Best Params\"]\n",
    "classification_cols = [\n",
    "    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\",\n",
    "    \"Confusion Matrix\", \"Best Params\"\n",
    "]\n",
    "\n",
    "# Exibição de resultados\n",
    "print(\"\\nResumo - Regressão:\\n\")\n",
    "if is_regressor.any():\n",
    "    cols = [c for c in regression_cols if c in summary_df.columns]\n",
    "    display(summary_df.loc[is_regressor, cols])\n",
    "else:\n",
    "    print(\"Nenhum modelo de regressão executado.\")\n",
    "\n",
    "print(\"\\nResumo - Classificação:\\n\")\n",
    "if is_classifier.any():\n",
    "    cols = [c for c in classification_cols if c in summary_df.columns]\n",
    "    display(summary_df.loc[is_classifier, cols])\n",
    "else:\n",
    "    print(\"Nenhum modelo de classificação executado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccc5ab",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
